{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clasificadores_propios_Semana24/5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL4awPhb27XM",
        "outputId": "719623c4-2fa3-428c-8433-c421fea55c96"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "%cd /content/gdrive/My\\ Drive/TESIS/autism-master/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "/content/gdrive/My Drive/TESIS/autism-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw2Jmtnb3FFI"
      },
      "source": [
        "%%capture\n",
        "import os\n",
        "import sys\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_validate\n",
        "!{sys.executable} -m pip install https://api.github.com/repos/paris-saclay-cds/ramp-workflow/zipball/master\n",
        "!{sys.executable} -m pip install scikit-learn seaborn nilearn\n",
        "from problem import get_cv\n",
        "from download_data import fetch_fmri_time_series\n",
        "from problem import get_train_data\n",
        "!pip install ripser\n",
        "from ripser import ripser\n",
        "from persim import plot_diagrams\n",
        "!pip install tensorflow_addons  \n",
        "!pip install gudhi\n",
        "import pickle as pkl\n",
        "from sklearn.ensemble import *\n",
        "from sklearn.svm import *\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV, KFold, ShuffleSplit\n",
        "from tensorflow import random_uniform_initializer as rui\n",
        "import gudhi.representations as tda\n",
        "import tensorflow as tf\n",
        "import os.path\n",
        "import itertools\n",
        "import h5py\n",
        "import tensorflow_addons  as tfa\n",
        "import gudhi              as gd\n",
        "from scipy.sparse           import csgraph\n",
        "from scipy.io               import loadmat\n",
        "from scipy.linalg           import eigh\n",
        "from sklearn.preprocessing  import LabelEncoder, OneHotEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "# Reduccion dimensionalidad\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "!pip install git+https://github.com/MathieuCarriere/perslay\n",
        "!pip install git+https://github.com/MathieuCarriere/sklearn-tda\n",
        "from perslay import PerslayModel\n",
        "from scipy.stats import beta\n",
        "!pip install nilearn\n",
        "from nilearn.connectome import ConnectivityMeasure\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install xgboost\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsGpHWgL-u8Z"
      },
      "source": [
        "atlass =  ['basc122', 'basc197', 'craddock_scorr_mean', 'power_2011']+['msdl', 'basc064', 'harvard_oxford_cort_prob_2mm']\n",
        "mattype = ['partial correlation', 'tangent', 'correlation']\n",
        "classif = ['xgb', 'rf']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LusqGzoa3M3n"
      },
      "source": [
        "sub_number = [3, 2, 0]\n",
        "atlas = atlass[sub_number[0]]\n",
        "mat = mattype[sub_number[1]]\n",
        "clf = classif[sub_number[2]]\n",
        "sys.path.append('./modelos_propios/'+atlas+'/'+mat+'/'+clf+'/')\n",
        "import classifier\n",
        "import feature_extractor\n",
        "from feature_extractor import *\n",
        "from classifier import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rJppqOq3Sco"
      },
      "source": [
        "data_train, labels_train = get_train_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfwi_ekM3UEn"
      },
      "source": [
        "def evaluation(X, y):\n",
        "    pipe = make_pipeline(FeatureExtractor(), Classifier())\n",
        "    cv = get_cv(X, y)\n",
        "    results = cross_validate(pipe, X, y, scoring=['roc_auc', 'accuracy', 'precision', 'recall'], cv=cv,\n",
        "                             verbose=4, return_train_score=True,\n",
        "                             n_jobs=-1)\n",
        "    \n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw2y4D2S3WYn",
        "outputId": "0f9b15af-4f1a-433f-c396-d0b4af3cf7ca"
      },
      "source": [
        "results = evaluation(data_train, labels_train)\n",
        "\n",
        "print((np.mean(results['train_roc_auc']),np.std(results['train_roc_auc'])))\n",
        "print('\\n')\n",
        "print(\"Validation score ROC-AUC: {:.3f} +- {:.3f}\".format(np.mean(results['test_roc_auc']),\n",
        "                                                          np.std(results['test_roc_auc'])))\n",
        "print(\"Validation score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['test_accuracy']),\n",
        "                                                           np.std(results['test_accuracy'])))\n",
        "print(\"Validation score precision: {:.3f} +- {:.3f}\".format(np.mean(results['test_precision']),\n",
        "                                                           np.std(results['test_precision'])))\n",
        "print(\"Validation score recall: {:.3f} +- {:.3f}\".format(np.mean(results['test_recall']),\n",
        "                                                           np.std(results['test_recall'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(0.9992166202441626, 0.0004436533681884938)\n",
            "\n",
            "\n",
            "Validation score ROC-AUC: 0.629 +- 0.024\n",
            "Validation score accuracy: 0.590 +- 0.023\n",
            "Validation score precision: 0.576 +- 0.026\n",
            "Validation score recall: 0.538 +- 0.034\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed: 61.7min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed: 61.7min finished\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}